This is an early stage project by Scott Williams

The goal of this project is to incorporate three use cases of generative AI to create short (and possibly long) form content to post on youtube shorts / tiktok / instagram. The content will mainly be news videos tailored to people in the age range of 18 to 30 years old and will summarize daily events in different news niches. The research will be conducted through a combination of web scraping tactics and filtering/ summarization using GPT-3.5. For actually writing the news scripts, I am currently working on incorporating a dual "agent" strategy where the summarized articles will be utilized by one instange of GPT to create a rough draft, then checked by another instance, acting as the editor, to see if the script is up to a certain standard or similar to a certain author's style. Additionally, the editor could say that more sources of a different nature (primary, secondary) are needed to make the article more informative. Essentially the two instances of GPT will function similar to a GAN, where one model acts as a generator, and the other as a descriminator. 

Next, I will use add more functionality to actually make the videos in an automated fashion using movie editing libraries such as pymovie, and the new Stability image-to-video, and OpenAI vision models. 

Finally, if I can get a desired video output, I will work on optimizing for API costs, since that will be a factor once I include the image and video models, which are quite expensive. 

-------------------
UPDATE (1/2/2024):
-------------------
A new class has been added called TTS_Wrapper() which incorporates google cloud's text-to-speech service, which is integrated via a custom api. The api key can be generated and saved as a json file when creating the custom service in google cloud. The path to this key will be specified as an environment variable called GOOGLE_APPLICATION_CREDENTIALS(see env.example). The wrapper class encapsulates the voice configuration and api call for simplicity and writes audio data in an mp3 or wav format to the 'output_audio_files' directory which is located in 'source'. 

> Here is a high level workflow of what the program does so far:
  - The user is prompted to ask a research question (see example below)
  - From this question, a list of potential google search queries are generated by GPT-3.5
  - These queries are used to source a variety of article urls and corresponding headlines
  - The headlines are checked by another instance of GPT-3.5 to determine their usefulness in answering the research question (this step avoids summarizing useless information in later steps and saves OpenAI credits)
  - The headlines and corresponding urls of articles that are deemed to be useful are then summarized into around 3 sentences by yet another instance of GPT-3.5 and the summaries contain information from the articles that help in answering the research question. (Note: each time the GPT model is called, a randomness setting, called temperature, can be configured and for this step, it is set to zero to avoid making up information in the summaries). Note, the scraper.py file contains the functions responsible for extracting text from an article's url, which is how the summaries are made. 
  - These summaries also have associated citations in a format that contains the publication's name and the approximate publication date. EG "[The New York Times, December 2023]".
  - Each summary is then passed into a final GPT-3.5 instance which takes all of the summaries and the research question, and generate text for our script.
  - The script is returned with multiple paragraphs/sections and for each section, the model also generates suggested visual suggestions for images or videos that correspond to what is being spoken at a certain point. (This is just a test and may change in the future to take in a list of images or videos and determine where to place them in the video instead of searching for what the model suggests).
  - Once the script is generated, I plan to create a "descriminator" class instance to check the generated script's quality and improve it to match my criteria or edit any errors, but as of now the first iteration of the script is used
  - The raw script text is then fed into the text to speech wrapper class using a few simple function calls, then the audio content is stored in a folder to access

> Example Output
Research Question: "What is happening between the naval forces of Iran, Yemen, and the US from december 10th 2023 to present?"
Sample Audio Output:
https://github.com/scott-williams-2002/NewsVideoGenerator/assets/97866224/76ca9ae6-bbfc-4701-b9f5-67e74f80a8d8




